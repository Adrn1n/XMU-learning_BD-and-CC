<!--
习题7

1、试述MapReduce的工作流程（需包括提交任务、Map、Shuffle、Reduce的过程）

2、试画出使用MapReduce来对英语句子“Whatever is worth doing is worth doing well”进行单词统计的过程。

3、Spark的出现是为了解决Hadoop MapReduce的不足，试列举Hadoop MapReduce的几个缺陷，并说明Spark具备哪些优点。

4、试述如下Spark的几个主要概念：RDD、DAG、阶段、分区、窄依赖、宽依赖。
-->
# 习题7

1. 试述MapReduce的工作流程（需包括提交任务、Map、Shuffle、Reduce的过程）

2. 试画出使用MapReduce来对英语句子“Whatever is worth doing is worth doing well”进行单词统计的过程。

3. Spark的出现是为了解决Hadoop MapReduce的不足，试列举Hadoop MapReduce的几个缺陷，并说明Spark具备哪些优点。

4. 试述如下Spark的几个主要概念：RDD、DAG、阶段、分区、窄依赖、宽依赖。

---

1. 
	- Job Submission: The client submits a job to the framework. The input data is split into blocks, and Map tasks are scheduled on nodes holding those blocks.
	- Map Phase: Each Map task processes its input split and outputs key-value pairs, Map tasks do not communicate with each other.
	- Shuffle Phase: The framework automatically partitions, sorts, and transfers intermediate key-value data from all Map tasks to the appropriate Reduce tasks. Data exchange is handled entirely by MapReduce.
	- Reduce Phase: Each Reduce task receives all values for its assigned keys, performas aggregation, and writes the final output. Reduce tasks also do not communicate with each other.
2. 
	   1. Map Phase:
	      (Whatever, 1)
	      (is, 1)
	      (worth, 1)
	      (doing, 1)
	      (is, 1)
	      (worth, 1)
	      (doing, 1)
	      (well, 1)
	   2. Shuffle Phase:
	      (Whatever, 1)
	      (is, (1, 1))
	      (worth, (1, 1))
	      (doing, (1, 1))
	      (well, 1)
	   3. Reduce Phase:
	      (Whatever, 1)
	      (is, 2)
	      (worth, 2)
	      (doing, 2)
	      (well, 1)
3. 
	- Hadoop MapReduce limitations:
		- High disk I/O
		- Poor support for iterative algorithms
		- High latency
		- Complex programming model and long job startup time
	- Spark advantages:
		- In-memory computing (RDD caching) greatly reduces disk I/O
		- Efficient for iterative and interactive workloads
		- Much faster execution due to DAG scheduling and memory reuse
		- Unified engine: supports SQL, streaming, ML, and graph processing in one framework
4. 
	 - RDD: A fault-tolerant, distributed collection of objects operated in parallel
	 - DAG: A Directed Acyclic Graph representing logical execution flow of transformations
	 - Stage: A set of tasks that can be executed without requiring a shuffle
	 - Partition: A chunk of data in an RDD processed by one task
	 - Narrow Dependency: Parent partitions map 1-to-1 to child partitions
	 - Wide Dependency: Child partitions depend on many parent partitions, requiring shuffle
