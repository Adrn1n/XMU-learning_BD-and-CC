<!--
习题10

1、 试述流数据的特点

2、 试述流计算流程与传统的数据处理流程之间的主要区别

3、 Storm的主要术语包括Streams、Spouts、Bolts、Topology和Stream Groupings，请分别描述这几个术语。

4、 试述Storm框架的工作流程。
-->
# 习题10

1. 试述流数据的特点

2. 试述流计算流程与传统的数据处理流程之间的主要区别

3. Storm的主要术语包括Streams、Spouts、Bolts、Topology和Stream Groupings，请分别描述这几个术语。

4. 试述Storm框架的工作流程。

---

1. 
	- Data arrives rapidly and continuously, with potentially infinite size.
	- Data originates from numerous sources and has complex formats.
	- The data volume is large, but storage is not a primary concern; once processed, it is either discarded or archived.
	- Emphasis is placed on the overall value of the data, rather than individual data points.
	- Data order may be inverted or incomplete, and the system cannot control the order of newly arriving data elements to be processed.
2. Traditional data processing typically involves collecting data and storing it in data management systems like relational databases, after which users interact with the data management system through query operations. Stream processing generally includes three stages: real-time data collection, real-time data computation, and real-time query services.
3. 
	- Streams: Storm describes stream data as an infinite sequence of Tuples. These Tuple sequences are created and processed in a distributed and parallel manner.
	- Spout: Storm considers each Stream to have a source and abstracts this source as a Spout.
	- Bolt: Storm abstracts the state transformation process of Streams as a Bolt. A Bolt can process Tuples and also send processed Tuples as new Streams to other Bolts.
	- Topology: Storm abstracts the network composed of Spouts and Bolts into a Topology, which can be submitted to a Storm cluster for execution. A Topology can be viewed as a stream transformation graph, where nodes are Spouts or Bolts, and edges indicate which Stream a Bolt subscribes to. When a Spout or Bolt emits a Tuple, it sends the Tuple to every Bolt that has subscribed to that Stream for processing.
	- Stream Groupings: Stream Groupings in Storm are used to inform the Topology how Tuples should be transferred between two components (e.g., between a Spout and a Bolt, or between different Bolts). Each Spout and Bolt can have multiple distributed tasks, and when and how a task sends Tuples is determined by Stream Groupings.
4. 
	   - Client Submits Topology: A client submits a Topology to the Nimbus daemon.
	   - Nimbus Stores Task Information: Nimbus then stores the task information, including the serialized Spout/Bolt instances, in the Zookeeper cluster.
	   - Supervisor Retrieves Tasks: Supervisor nodes continuously monitor Zookeeper. They retrieve the tasks assigned to them and initiate Worker processes.
	   - Worker Executes Tasks: Each Worker process, running on a Supervisor node, deserializes the Spout/Bolt components and executes the specific tasks assigned to it.
